{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d111c0bb-e01a-450a-b1b7-1e580497ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b02d9a2-209b-4ff8-8dc6-e7d74584bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../swift.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8193f74e-e628-445a-9cf1-3c0c40827cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "08cf362c-83a7-4baa-8906-a35df301ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9981da9a-2505-4712-a1e1-c0094282c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_copy.copy()[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4b07b45e-fe96-4ec3-9fa5-e20fb1dcb6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transaction Ref    False\n",
       "Originator         False\n",
       "Beneficiary        False\n",
       "Type               False\n",
       "Currency           False\n",
       "Value              False\n",
       "Flag               False\n",
       "Fulldate           False\n",
       "Intermediate       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cc42b363-48e6-49f6-8efe-3c7afa77f29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.82 s, sys: 221 ms, total: 2.04 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = df_copy.copy()[:size]\n",
    "df['Fulldate'] = pd.to_datetime(df['Fulldate'])\n",
    "\n",
    "df['OriginatorCountry'] = df['Originator'].str.strip().str[4:6]\n",
    "df['IntermediateCountry'] = df['Intermediate'].str.strip().str[4:6]\n",
    "df['BeneficiaryCountry'] = df['Originator'].str.strip().str[4:6]\n",
    "\n",
    "df['OriginatorCountry_BeneficiaryCountry'] = df['OriginatorCountry']+df['BeneficiaryCountry']\n",
    "df['OriginatorCountry_IntermediateCountry'] = df['OriginatorCountry']+df['IntermediateCountry']\n",
    "df['IntermediateCountry_BeneficiaryCountry'] = df['IntermediateCountry']+df['BeneficiaryCountry']\n",
    "df['OriginatorCountry_IntermediateCountry_BeneficiaryCountry'] = df['OriginatorCountry']+df['IntermediateCountry']+df['BeneficiaryCountry']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b861a-e5d3-453e-83ae-c37839a14ce6",
   "metadata": {},
   "source": [
    "# Features Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "14075b31-15bd-465c-a15c-c43f39269133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLatency(x,name_col):\n",
    "    return (x[name_col]-x[name_col].shift(1)).dt.total_seconds().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d1cfb5a6-9a71-4958-aab3-ace6df4373f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_circuit(x):\n",
    "    return sum(df.loc[x.index,'Beneficiary']==df.loc[x.index,'Intermediate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b5b465e8-db9c-4b56-90ee-f87a9a998a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_circuit(x):\n",
    "    return sum(x.str[:2]!=x.str[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9a61952a-f306-4fb8-a7fe-02992b24cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_features_client(type_client,period,relationship):\n",
    "    \n",
    "    cols_start = df.columns\n",
    "    \n",
    "    groupby = []\n",
    "        \n",
    "    if period == '10Days':\n",
    "        groupby = type_client+[pd.Grouper(key='Fulldate', axis=0, freq='10D')]\n",
    "    elif period == 'Month':\n",
    "        groupby = type_client+[pd.Grouper(key='Fulldate', axis=0, freq='30D')]\n",
    "    elif period == 'Global':\n",
    "        groupby = type_client\n",
    "\n",
    "    name = period+'_'+'_'.join(type_client)\n",
    "    \n",
    "    print(groupby)\n",
    "    #FREQUENCY\n",
    "    \n",
    "    df['frequency_'+name] = df.groupby(groupby)['Value'].transform('count')\n",
    "    \n",
    "    #AMOUNT\n",
    "    \n",
    "    df['sum_value_'+name] = df.groupby(groupby)['Value'].transform('sum')\n",
    "    df['max_value_'+name] = df.groupby(groupby)['Value'].transform('max')\n",
    "    df['min_value_'+name] = df.groupby(groupby)['Value'].transform('min')\n",
    "    df['avg_value_'+name] = df.groupby(groupby)['Value'].transform('sum')/df['frequency_'+name]\n",
    "    \n",
    "    if relationship == False:\n",
    "        # LATENCY\n",
    "        #print('latency')\n",
    "        df['latency_'+name] = df.groupby(groupby, as_index=False).apply(getLatency,name_col='Fulldate').reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "        # NB RELATION\n",
    "        #print('nb relation')\n",
    "        if type_client[0] == 'Originator':\n",
    "            df['number_relation_'+name] = df.groupby(['Originator'])['Beneficiary'].transform('nunique')\n",
    "        elif type_client[0] =='Beneficiary':\n",
    "            df['number_relation_'+name] = df.groupby(['Beneficiary'])['Originator'].transform('nunique')\n",
    "        \n",
    "    # NB OF DISTINCT CURRENCY\n",
    "    #print('currency 1')\n",
    "    \n",
    "    df['number_distinct_currency_'+name] = df.groupby(['Originator'])['Currency'].transform('nunique')\n",
    "    \n",
    "    # NB WITH CURRENT CURRENCY\n",
    "    #print('currency 2')\n",
    "        \n",
    "    df['frequency_with_currency_'+name] = df.groupby(groupby+['Currency'])['Value'].transform('count')\n",
    "    \n",
    "    if relationship == False:\n",
    "    \n",
    "        # NB OF DISTINCT COUNTRIES\n",
    "        #print('country 1')\n",
    "\n",
    "        if type_client[0] == 'Originator' :\n",
    "            df['number_distinct_country_'+name] = df.groupby(['Originator'])['BeneficiaryCountry'].transform('nunique')\n",
    "        elif type_client[0] =='Beneficiary':\n",
    "            df['number_distinct_country_'+name] = df.groupby(['Beneficiary'])['OriginatorCountry'].transform('nunique')\n",
    "\n",
    "        # NB WITH CURRENT COUNTRY\n",
    "       # print('country 2')\n",
    "\n",
    "        if type_client[0] == 'Originator':\n",
    "            df['frequency_to_Beneficiary_Country_'+name] = df.groupby(groupby+['BeneficiaryCountry'])['Value'].transform('count')\n",
    "\n",
    "        elif type_client[0] =='Beneficiary':\n",
    "            df['frequency_to_Originator_Country_'+name] = df.groupby(groupby+['OriginatorCountry'])['Value'].transform('count')\n",
    "\n",
    "\n",
    "        # NB WITH INTERMEDIATE\n",
    "        #print('intermediate 1')\n",
    "\n",
    "        if type_client[0] == 'Originator':\n",
    "            df['number_with_intermediate_'+name] = df.groupby(['Originator'])['IntermediateCountry_BeneficiaryCountry'].transform(get_circuit)\n",
    "        elif type_client[0] =='Beneficiary' :\n",
    "            df['number_with_intermediate_'+name] = df.groupby(['Beneficiary'])['IntermediateCountry_BeneficiaryCountry'].transform(get_circuit)\n",
    "\n",
    "        # NB DISTINCT CIRCRUIT\n",
    "        #print('intermediate 2')\n",
    "\n",
    "        if type_client[0] == 'Originator':\n",
    "            df['number_dinstinct_circuit_with_intermediate_'+name] = df.groupby(['Originator'])['IntermediateCountry_BeneficiaryCountry'].transform('nunique')\n",
    "        elif type_client[0] =='Beneficiary':\n",
    "            df['number_dinstinct_circuit_with_intermediate_'+name] = df.groupby(['Beneficiary'])['OriginatorCountry_IntermediateCountry'].transform('nunique')\n",
    "\n",
    "        # NB CURRENT CIRCRUIT\n",
    "        #print('intermediate 3')\n",
    "\n",
    "        if type_client[0] == 'Originator':\n",
    "            df['number_current_circuit_with_intermediate_'+name] = df.groupby(['Originator','IntermediateCountry_BeneficiaryCountry'])['Value'].transform('count')\n",
    "        elif type_client[0] =='Beneficiary':\n",
    "            df['number_current_circuit_with_intermediate_'+name] = df.groupby(['Beneficiary','OriginatorCountry_IntermediateCountry'])['Value'].transform('count')\n",
    "\n",
    "    \n",
    "    cols_end = df.columns\n",
    "    \n",
    "    new_cols = list(set(cols_end) - set(cols_start))\n",
    "    \n",
    "    return new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c08cd7-332c-43d3-a27d-7734721be56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beneficiary']\n",
      "['Beneficiary', TimeGrouper(key='Fulldate', freq=<10 * Days>, axis=0, sort=True, closed='left', label='left', how='mean', convention='e', origin='start_day')]\n",
      "['Beneficiary', TimeGrouper(key='Fulldate', freq=<30 * Days>, axis=0, sort=True, closed='left', label='left', how='mean', convention='e', origin='start_day')]\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "array = []\n",
    "name_configuration = []\n",
    "\n",
    "array.append(base_features_client(['Beneficiary'],'Global',False))\n",
    "array.append(base_features_client(['Beneficiary'],'10Days',False))\n",
    "array.append(base_features_client(['Beneficiary'],'Month',False))\n",
    "name_configuration.append('Beneficiary-Global')\n",
    "name_configuration.append('Beneficiary-10Days')\n",
    "name_configuration.append('Beneficiary-Month')\n",
    "\n",
    "array.append(base_features_client(['Originator'],'Global',False))\n",
    "array.append(base_features_client(['Originator'],'10Days',False))\n",
    "array.append(base_features_client(['Originator'],'Month',False))\n",
    "name_configuration.append('Originator-Global')\n",
    "name_configuration.append('Originator-10Days')\n",
    "name_configuration.append('Originator-Month')\n",
    "\n",
    "array.append(base_features_client(['Intermediate'],'Global',False))\n",
    "array.append(base_features_client(['Intermediate'],'10Days',False))\n",
    "array.append(base_features_client(['Intermediate'],'Month',False))\n",
    "name_configuration.append('Intermediate-Global')\n",
    "name_configuration.append('Intermediate-10Days')\n",
    "name_configuration.append('Intermediate-Month')\n",
    "\n",
    "array.append(base_features_client(['Originator','Beneficiary'],'Global',True))\n",
    "array.append(base_features_client(['Originator','Beneficiary'],'10Days',True))\n",
    "array.append(base_features_client(['Originator','Beneficiary'],'Month',True))\n",
    "name_configuration.append('Originator-Beneficiary-Global')\n",
    "name_configuration.append('Originator-Beneficiary-10Days')\n",
    "name_configuration.append('Originator-Beneficiary-Month')\n",
    "\n",
    "array.append(base_features_client(['Originator','Intermediate'],'Global',True))\n",
    "array.append(base_features_client(['Originator','Intermediate'],'10Days',True))\n",
    "array.append(base_features_client(['Originator','Intermediate'],'Month',True))\n",
    "name_configuration.append('Originator-Intermediate-Global')\n",
    "name_configuration.append('Originator-Intermediate-10Days')\n",
    "name_configuration.append('Originator-Intermediate-Month')\n",
    "\n",
    "array.append(base_features_client(['Intermediate','Beneficiary'],'Global',True))\n",
    "array.append(base_features_client(['Intermediate','Beneficiary'],'10Days',True))\n",
    "array.append(base_features_client(['Intermediate','Beneficiary'],'Month',True))\n",
    "name_configuration.append('Intermediate-Beneficiary-Global')\n",
    "name_configuration.append('Intermediate-Beneficiary-10Days')\n",
    "name_configuration.append('Intermediate-Beneficiary-Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e21503-ef47-44ee-9500-456933dc7b56",
   "metadata": {},
   "source": [
    "# Features Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de679a5-68a8-4352-bba9-a29ed7f93aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_features_transaction(column,period):\n",
    "    \n",
    "    cols_start = df.columns\n",
    "        \n",
    "    if period == '10Days':\n",
    "        groupby = [column,pd.Grouper(key=name_col_date, axis=0, freq='10D')]\n",
    "    elif period == 'Month':\n",
    "        groupby = [column,pd.Grouper(key=name_col_date, axis=0, freq='30D')]\n",
    "    elif period == 'Global':\n",
    "        groupby = column\n",
    "\n",
    "    name = period+'_'+'_'.join(column)\n",
    "    \n",
    "    #FREQUENCY\n",
    "    \n",
    "    df['frequency_'+name] = df.groupby(groupby)['Value'].transform('count')\n",
    "    \n",
    "    #AMOUNT\n",
    "    \n",
    "    df['sum_value_'+name] = df.groupby(groupby)['Value'].transform('sum')\n",
    "    df['max_value_'+name] = df.groupby(groupby)['Value'].transform('max')\n",
    "    df['min_value_'+name] = df.groupby(groupby)['Value'].transform('min')\n",
    "    df['avg_value_'+name] = df.groupby(groupby)['Value'].transform('sum')/df['frequency_'+name]\n",
    "    \n",
    "    # LATENCY\n",
    "    df['latency_'+name] = df.groupby(groupby, as_index=False).apply(getLatency,name_col='Fulldate').reset_index(level=0, drop=True)\n",
    "    \n",
    "    # NB RELATION\n",
    "    df['number_relation_originator_'+name] = df.groupby(groupby)['Originator'].transform('nunique')\n",
    "    df['number_relation_beneficiary_'+name] = df.groupby(groupby)['Beneficiary'].transform('nunique')\n",
    "    df['number_relation_intermediate_'+name] = df.groupby(groupby)['Intermediate'].transform('nunique')\n",
    "        \n",
    "    # NB OF DISTINCT CURRENCY\n",
    "    \n",
    "    if column != 'Currency':\n",
    "        df['number_distinct_currency_'+name] = df.groupby(groupby)['Currency'].transform('nunique')\n",
    "        df['frequency_with_currency_'+name] = df.groupby(groupby+['Currency'])['Value'].transform('count')\n",
    "    \n",
    "    \n",
    "    # NB OF DISTINCT COUNTRIES\n",
    "    \n",
    "    if column not in ['OriginatorCountry','BeneficiaryCountry','IntermediateCountry']:\n",
    "        df['number_distinct_originator_country_'+name] = df.groupby(groupby)['OriginatorCountry'].transform('nunique')\n",
    "        df['number_distinct_beneficiary_country_'+name] = df.groupby(groupby)['BeneficiaryCountry'].transform('nunique')\n",
    "        df['number_distinct_intermediate_country_'+name] = df.groupby(groupby)['IntermediateCountry'].transform('nunique')\n",
    "        \n",
    "        df['number_current_originator_country_'+name] = df.groupby(groupby)['OriginatorCountry'].transform('count')\n",
    "        df['number_current_beneficiary_country_'+name] = df.groupby(groupby)['BeneficiaryCountry'].transform('count')\n",
    "        df['number_current_intermediate_country_'+name] = df.groupby(groupby)['IntermediateCountry'].transform('count')\n",
    "            \n",
    "    \n",
    "    # NB WITH INTERMEDIATE\n",
    "    df['number_with_intermediate_'+name] = df.groupby(groupby)['IntermediateCountry_BeneficiaryCountry'].transform(get_circuit)\n",
    "    \n",
    "    # NB DISTINCT CIRCRUIT\n",
    "    \n",
    "    df['number_dinstinct_circuit_with_intermediate_'+name] = df.groupby(groupby)['IntermediateCountry_BeneficiaryCountry'].transform('nunique')\n",
    "        \n",
    "    # NB CURRENT CIRCRUIT\n",
    "    \n",
    "    df['number_current_circuit_intermediateCountry_beneficiaryCountry_'+name] = df.groupby(groupby+['IntermediateCountry_BeneficiaryCountry'])['Value'].transform('count')\n",
    "    df['number_current_circuit_originatorCountry_intermediateCountry_'+name] = df.groupby(groupby+['OriginatorCountry_IntermediateCountry'])['Value'].transform('count')\n",
    "    df['number_current_circuit_originatorCountry_beneficiaryCountry_'+name] = df.groupby(groupby+['OriginatorCountry_BeneficiaryCountry'])['Value'].transform('count')\n",
    "    df['number_current_circuit_originatorCountry_intermediateCountry_beneficiaryCountry_'+name] = df.groupby(groupby+['OriginatorCountry_IntermediateCountry_BeneficiaryCountry'])['Value'].transform('count')\n",
    "    \n",
    "    cols_end = df.columns\n",
    "    \n",
    "    new_cols = list(set(cols_end) - set(cols_start))\n",
    "    \n",
    "    return new_cols\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32691512-ec9c-4320-b99c-8fa809952c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "base_feature = []\n",
    "array.extend(base_features_transaction(['Currency'],'Global'))\n",
    "name_configuration.append('Currency-Global')\n",
    "array.extend(base_features_transaction(['OriginatorCountry'],'Global'))\n",
    "name_configuration.append('OriginatorCountry-Global')\n",
    "array.extend(base_features_transaction(['BeneficiaryCountry'],'Global'))\n",
    "name_configuration.append('BeneficiaryCountry-Global')\n",
    "array.extend(base_features_transaction(['IntermediateCountry'],'Global'))\n",
    "name_configuration.append('IntermediateCountry-Global')\n",
    "array.extend(base_features_transaction(['Type'],'Global'))\n",
    "name_configuration.append('Type-Global')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff85a14-7b4f-4dee-9302-3aeefb9cd9ca",
   "metadata": {},
   "source": [
    "# Transaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec6bd6-6287-4d69-8c92-9b5637ad8b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "base_feature.extend(list(df_copy.select_dtypes(include=np.number).columns))\n",
    "cols_start = df.columns\n",
    "\n",
    "df['Hour'] = df['Fulldate'].dt.hour\n",
    "df['Week_of_year'] = df['Fulldate'].dt.week\n",
    "df['day_of_week'] = df['Fulldate'].dt.dayofweek\n",
    "df['day_of_year'] = df['Fulldate'].dt.dayofyear\n",
    "df['quarter'] = df['Fulldate'].dt.quarter\n",
    "df['year'] = df['Fulldate'].dt.year\n",
    "df['month'] = df['Fulldate'].dt.month\n",
    "df['day'] = df['Fulldate'].dt.day\n",
    "df['is_month_start'] = df['Fulldate'].dt.is_month_start\n",
    "df['is_month_start'] = df['is_month_start'].map({True: 1, False:0})\n",
    "df['is_month_end'] = df['Fulldate'].dt.is_month_end\n",
    "df['is_month_end'] = df['is_month_end'].map({True: 1, False:0})\n",
    "cols_end = df.columns          \n",
    "new_cols = list(set(cols_end) - set(cols_start))\n",
    "\n",
    "base_feature.extend(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3abc32-95e6-4a7d-ab47-04cc9e485e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f052cb-bbbd-49e1-a169-392c7fcf80f5",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e6d79-4fe0-452a-b47e-9ab3e1e24d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from itertools import combinations\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90334542-68ef-4a2f-9046-0ac706d9b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.select_dtypes(include=np.number)\n",
    "y = df['Flag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b0225-e0ab-4e99-b24d-296f8d7277f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test,y_pred,output_dict=True )\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "print('les fraudes : ')\n",
    "print('bien trouvée TP : ',TP)\n",
    "print('pas trouvée FN : ',FN) \n",
    "print('les normaux')\n",
    "print('bien trouvée TN : ',TN)\n",
    "print('pas trouvée FP : ',FP)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63b8a7-fb48-4934-874d-be8ba5af52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = BalancedRandomForestClassifier(n_estimators=30)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test,y_pred,output_dict=True )\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "print('les fraudes : ')\n",
    "print('bien trouvée TP : ',TP)\n",
    "print('pas trouvée FN : ',FN) \n",
    "print('les normaux')\n",
    "print('bien trouvée TN : ',TN)\n",
    "print('pas trouvée FP : ',FP)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95106068-2e8f-40f0-88c8-f841a04c0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "modelRF = RandomForestClassifier(n_estimators=30,bootstrap = True,max_features = 'sqrt')\n",
    "\n",
    "modelRF.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelRF.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test,y_pred,output_dict=True )\n",
    "report\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "print('les fraudes : ')\n",
    "print('bien trouvée TP : ',TP)\n",
    "print('pas trouvée FN : ',FN)\n",
    "print('les normaux')\n",
    "print('bien trouvée TN : ',TN)\n",
    "print('pas trouvée FP : ',FP)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fd735e-04a4-403a-9214-e669a69dda5f",
   "metadata": {},
   "source": [
    "# Approche"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa291aa-b96b-4020-84b6-5dd05567a470",
   "metadata": {},
   "source": [
    "## Decision Tree training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967feae1-c5e8-4600-bdc5-1f35a6c8ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred_array = []\n",
    "y_pred_array_f1_score = []\n",
    "models = []\n",
    "models_f1_score = []\n",
    "\n",
    "\n",
    "\n",
    "for idx,cols in enumerate(name_configuration):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train[array[idx]+base_feature], y_train)\n",
    "    models.append(model)\n",
    "    \n",
    "    y_pred = model.predict(X_test[array[idx]+base_feature])\n",
    "    \n",
    "    report = classification_report(y_test,y_pred,output_dict=True )\n",
    "\n",
    "    models_f1_score.append(report['True']['f1-score'])\n",
    "    y_pred_array.append(np.multiply(y_pred, 1))\n",
    "    y_pred_array_f1_score.append(np.multiply(y_pred, round(report['True']['f1-score'],2)))\n",
    "    \n",
    "    print(name_configuration[idx], 'base & ',round(report['True']['precision'],2),'&',round(report['True']['recall'],2),'&',round(report['True']['f1-score'],2),'\\\\\\ \\hline')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692fd050-e931-4260-a5b8-8085f8297d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25ec1f-a1df-4e7b-9e8e-54bb203f061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for alpha in range(10):\n",
    "    maxF1 = 0\n",
    "    alphaMax = 0\n",
    "    threshold = 0\n",
    "    listf1 = []\n",
    "    listIndex = []\n",
    "    y_pred_final = np.sum(y_pred_array_f1_score, 0)/(alpha+np.sum(y_pred_array, 0))\n",
    "    y_pred_final = (y_pred_final - np.min(y_pred_final)) / (np.max(y_pred_final) - np.min(y_pred_final))\n",
    "    y_pred_final[np.isnan(y_pred_final)] = 0\n",
    "    for i in np.arange(0,1,0.005):\n",
    "        y_pred = np.where(y_pred_final>=i, 1, 0)\n",
    "        report = classification_report(y_test,y_pred,output_dict=True )\n",
    "        listf1.append(report['True']['f1-score'])\n",
    "        listIndex.append(i)\n",
    "        # print( i,' : ',report['True'])\n",
    "    if np.max(listf1) > maxF1:\n",
    "        maxF1 = np.max(listf1)\n",
    "        alphaMax = alpha\n",
    "        threshold = listIndex[np.argmax(listf1)]\n",
    "    print(alpha,':',np.max(listf1))\n",
    "print('----------------')\n",
    "print('best alpha : ',alphaMax)\n",
    "print('best f1-score : ',maxF1)\n",
    "print('best threshold : ',threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40517acf-6a24-4eab-9b8c-84391db56dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = np.sum(y_pred_array_f1_score, 0)/(alphaMax+np.sum(y_pred_array, 0))\n",
    "y_pred_final = (y_pred_final - np.min(y_pred_final)) / (np.max(y_pred_final) - np.min(y_pred_final))\n",
    "y_pred_final[np.isnan(y_pred_final)] = 0\n",
    "\n",
    "y_pred = np.where(y_pred_final>=threshold, 1, 0)\n",
    "report = classification_report(y_test,y_pred,output_dict=True )\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e52f82-b10b-4e19-8bcb-15bdc7aca9e5",
   "metadata": {},
   "source": [
    "# Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dca82a-6cb1-4390-9af5-5a245748bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_conf = []\n",
    "for i in np.transpose(y_pred_array):\n",
    "    arr_conf.append([name_configuration[j] for j,x in enumerate(i) if x>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b4cee-1fba-4c45-8e02-8999009943a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.loc[X_test.index] \n",
    "new_df['Fraudulent Score'] = y_pred_final\n",
    "new_df['Decision Trees'] = arr_conf\n",
    "new_df = new_df.sort_values(by=['Fraudulent Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df6f3b-ecee-4ff9-a2ea-4aef563c4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
